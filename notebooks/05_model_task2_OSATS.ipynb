{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos with frames: 30\n"
     ]
    }
   ],
   "source": [
    "LABEL_PATH = Path(\"../data/labels/labels_task2.csv\")\n",
    "FRAME_DIR = Path(\"../data/frames\")\n",
    "\n",
    "df = pd.read_csv(LABEL_PATH)\n",
    "available_videos = {p.name for p in FRAME_DIR.iterdir() if p.is_dir() and any(p.glob(\"*.jpg\"))}\n",
    "df = df[df[\"VIDEO\"].isin(available_videos)].reset_index(drop=True)\n",
    "print(f\"Number of videos with frames: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSDataset(Dataset):\n",
    "    def __init__(self, dataframe, frame_dir, transform=None, sequence_length=16):\n",
    "        self.data = dataframe.copy()\n",
    "        self.frame_dir = frame_dir\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.osats_cols = [col for col in dataframe.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "        for col in self.osats_cols:\n",
    "            self.data[col] = self.data[col].clip(0, 4).astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        video_id = row[\"VIDEO\"]\n",
    "        y = row[self.osats_cols].values.astype(np.int64)\n",
    "        path = self.frame_dir / video_id\n",
    "\n",
    "        frames = sorted(path.glob(\"*.jpg\"))\n",
    "        selected = frames[:self.sequence_length]\n",
    "        if len(selected) == 0:\n",
    "            raise IndexError(f\"No frames for video {video_id}\")\n",
    "        while len(selected) < self.sequence_length:\n",
    "            selected.append(selected[-1])\n",
    "\n",
    "        images = [self.transform(Image.open(f).convert(\"RGB\")) for f in selected]\n",
    "        return torch.stack(images), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transforms para imagens (compatível com CNNs e ResNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Colunas OSATS (as 8 que vais prever)\n",
    "osats_cols = [col for col in df.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "# Criar uma coluna auxiliar com a média arredondada das OSATS para estratificação\n",
    "df[\"OSATS_MEAN_LABEL\"] = df[osats_cols].mean(axis=1).round().astype(int)\n",
    "\n",
    "# Divisão 70% treino, 30% temp (com estratificação)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=42, stratify=df[\"OSATS_MEAN_LABEL\"]\n",
    ")\n",
    "\n",
    "# Divisão 15% validação, 15% teste (sem stratify para evitar erro)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Criação dos datasets\n",
    "train_dataset = OSATSDataset(train_df, FRAME_DIR, transform)\n",
    "val_dataset = OSATSDataset(val_df, FRAME_DIR, transform)\n",
    "test_dataset = OSATSDataset(test_df, FRAME_DIR, transform)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
    "\n",
    "class CNNModel_1(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_1, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 100)\n",
    "        kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "        self.act2 = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.act2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_2(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_2, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm2d, Dropout\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel_3(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_3, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 600)\n",
    "        self.drop = Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Dropout2d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel_4(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_4, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets[:, 0]\n",
    "\n",
    "            if outputs.shape[0] != targets.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: outputs {outputs.shape} vs targets {targets.shape}\")\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets[:, 0]\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 3.5515\n",
      "Epoch [2/100], Loss: 3.3976\n",
      "Epoch [3/100], Loss: 3.2726\n",
      "Epoch [4/100], Loss: 3.2726\n",
      "Epoch [5/100], Loss: 3.2726\n",
      "Epoch [6/100], Loss: 3.2726\n",
      "Epoch [7/100], Loss: 3.3976\n",
      "Epoch [8/100], Loss: 3.3976\n",
      "Epoch [9/100], Loss: 3.3976\n",
      "Epoch [10/100], Loss: 3.3976\n",
      "Epoch [11/100], Loss: 3.2726\n",
      "Epoch [12/100], Loss: 3.3976\n",
      "Epoch [13/100], Loss: 3.3976\n",
      "Epoch [14/100], Loss: 3.3976\n",
      "Epoch [15/100], Loss: 3.2726\n",
      "Epoch [16/100], Loss: 3.3976\n",
      "Epoch [17/100], Loss: 3.2726\n",
      "Epoch [18/100], Loss: 3.3976\n",
      "Epoch [19/100], Loss: 3.3976\n",
      "Epoch [20/100], Loss: 3.3976\n",
      "Epoch [21/100], Loss: 3.3976\n",
      "Epoch [22/100], Loss: 3.2726\n",
      "Epoch [23/100], Loss: 3.2726\n",
      "Epoch [24/100], Loss: 3.2726\n",
      "Epoch [25/100], Loss: 3.3976\n",
      "Epoch [26/100], Loss: 3.2726\n",
      "Epoch [27/100], Loss: 3.3976\n",
      "Epoch [28/100], Loss: 3.3976\n",
      "Epoch [29/100], Loss: 3.2726\n",
      "Epoch [30/100], Loss: 3.2726\n",
      "Epoch [31/100], Loss: 3.3976\n",
      "Epoch [32/100], Loss: 3.2726\n",
      "Epoch [33/100], Loss: 3.3976\n",
      "Epoch [34/100], Loss: 3.3976\n",
      "Epoch [35/100], Loss: 3.3976\n",
      "Epoch [36/100], Loss: 3.3976\n",
      "Epoch [37/100], Loss: 3.3976\n",
      "Epoch [38/100], Loss: 3.2726\n",
      "Epoch [39/100], Loss: 3.3976\n",
      "Epoch [40/100], Loss: 3.3976\n",
      "Epoch [41/100], Loss: 3.3976\n",
      "Epoch [42/100], Loss: 3.3976\n",
      "Epoch [43/100], Loss: 3.2726\n",
      "Epoch [44/100], Loss: 3.3976\n",
      "Epoch [45/100], Loss: 3.3976\n",
      "Epoch [46/100], Loss: 3.2726\n",
      "Epoch [47/100], Loss: 3.2726\n",
      "Epoch [48/100], Loss: 3.3976\n",
      "Epoch [49/100], Loss: 3.3976\n",
      "Epoch [50/100], Loss: 3.2726\n",
      "Epoch [51/100], Loss: 3.3976\n",
      "Epoch [52/100], Loss: 3.3976\n",
      "Epoch [53/100], Loss: 3.3976\n",
      "Epoch [54/100], Loss: 3.3976\n",
      "Epoch [55/100], Loss: 3.3976\n",
      "Epoch [56/100], Loss: 3.3976\n",
      "Epoch [57/100], Loss: 3.2726\n",
      "Epoch [58/100], Loss: 3.3976\n",
      "Epoch [59/100], Loss: 3.3976\n",
      "Epoch [60/100], Loss: 3.3976\n",
      "Epoch [61/100], Loss: 3.3976\n",
      "Epoch [62/100], Loss: 3.2726\n",
      "Epoch [63/100], Loss: 3.2726\n",
      "Epoch [64/100], Loss: 3.3976\n",
      "Epoch [65/100], Loss: 3.2726\n",
      "Epoch [66/100], Loss: 3.3976\n",
      "Epoch [67/100], Loss: 3.2726\n",
      "Epoch [68/100], Loss: 3.3976\n",
      "Epoch [69/100], Loss: 3.3976\n",
      "Epoch [70/100], Loss: 3.2726\n",
      "Epoch [71/100], Loss: 3.3976\n",
      "Epoch [72/100], Loss: 3.3976\n",
      "Epoch [73/100], Loss: 3.3976\n",
      "Epoch [74/100], Loss: 3.3976\n",
      "Epoch [75/100], Loss: 3.3976\n",
      "Epoch [76/100], Loss: 3.3976\n",
      "Epoch [77/100], Loss: 3.3976\n",
      "Epoch [78/100], Loss: 3.2726\n",
      "Epoch [79/100], Loss: 3.2726\n",
      "Epoch [80/100], Loss: 3.3976\n",
      "Epoch [81/100], Loss: 3.3976\n",
      "Epoch [82/100], Loss: 3.3976\n",
      "Epoch [83/100], Loss: 3.3976\n",
      "Epoch [84/100], Loss: 3.2726\n",
      "Epoch [85/100], Loss: 3.3976\n",
      "Epoch [86/100], Loss: 3.3976\n",
      "Epoch [87/100], Loss: 3.2726\n",
      "Epoch [88/100], Loss: 3.3976\n",
      "Epoch [89/100], Loss: 3.3976\n",
      "Epoch [90/100], Loss: 3.3976\n",
      "Epoch [91/100], Loss: 3.3976\n",
      "Epoch [92/100], Loss: 3.3976\n",
      "Epoch [93/100], Loss: 3.2726\n",
      "Epoch [94/100], Loss: 3.2726\n",
      "Epoch [95/100], Loss: 3.3976\n",
      "Epoch [96/100], Loss: 3.3976\n",
      "Epoch [97/100], Loss: 3.3976\n",
      "Epoch [98/100], Loss: 3.2726\n",
      "Epoch [99/100], Loss: 3.2726\n",
      "Epoch [100/100], Loss: 3.3976\n",
      "Validação - Modelo 1\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 1\n",
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model1 = CNNModel_1(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model1 = train_model(model1, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 1\")\n",
    "evaluate_model(model1, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 1\")\n",
    "evaluate_model(model1, test_loader)\n",
    "\n",
    "# Guardar modelo com nome especificado\n",
    "torch.save(model1.state_dict(), \"../outputs/models/model_task2_cnn1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.2780\n",
      "Epoch [2/100], Loss: 1.1471\n",
      "Epoch [3/100], Loss: 1.0207\n",
      "Epoch [4/100], Loss: 0.8331\n",
      "Epoch [5/100], Loss: 0.6566\n",
      "Epoch [6/100], Loss: 0.5938\n",
      "Epoch [7/100], Loss: 0.4651\n",
      "Epoch [8/100], Loss: 0.5090\n",
      "Epoch [9/100], Loss: 0.3157\n",
      "Epoch [10/100], Loss: 0.3054\n",
      "Epoch [11/100], Loss: 0.2842\n",
      "Epoch [12/100], Loss: 0.1382\n",
      "Epoch [13/100], Loss: 0.1478\n",
      "Epoch [14/100], Loss: 0.1138\n",
      "Epoch [15/100], Loss: 0.0969\n",
      "Epoch [16/100], Loss: 0.0678\n",
      "Epoch [17/100], Loss: 0.0536\n",
      "Epoch [18/100], Loss: 0.0413\n",
      "Epoch [19/100], Loss: 0.0315\n",
      "Epoch [20/100], Loss: 0.0286\n",
      "Epoch [21/100], Loss: 0.0262\n",
      "Epoch [22/100], Loss: 0.0334\n",
      "Epoch [23/100], Loss: 0.0216\n",
      "Epoch [24/100], Loss: 0.0203\n",
      "Epoch [25/100], Loss: 0.0154\n",
      "Epoch [26/100], Loss: 0.0149\n",
      "Epoch [27/100], Loss: 0.0125\n",
      "Epoch [28/100], Loss: 0.0122\n",
      "Epoch [29/100], Loss: 0.0099\n",
      "Epoch [30/100], Loss: 0.0092\n",
      "Epoch [31/100], Loss: 0.0084\n",
      "Epoch [32/100], Loss: 0.0101\n",
      "Epoch [33/100], Loss: 0.0070\n",
      "Epoch [34/100], Loss: 0.0070\n",
      "Epoch [35/100], Loss: 0.0079\n",
      "Epoch [36/100], Loss: 0.0063\n",
      "Epoch [37/100], Loss: 0.0060\n",
      "Epoch [38/100], Loss: 0.0067\n",
      "Epoch [39/100], Loss: 0.0053\n",
      "Epoch [40/100], Loss: 0.0051\n",
      "Epoch [41/100], Loss: 0.0044\n",
      "Epoch [42/100], Loss: 0.0041\n",
      "Epoch [43/100], Loss: 0.0038\n",
      "Epoch [44/100], Loss: 0.0036\n",
      "Epoch [45/100], Loss: 0.0034\n",
      "Epoch [46/100], Loss: 0.0035\n",
      "Epoch [47/100], Loss: 0.0042\n",
      "Epoch [48/100], Loss: 0.0036\n",
      "Epoch [49/100], Loss: 0.0032\n",
      "Epoch [50/100], Loss: 0.0027\n",
      "Epoch [51/100], Loss: 0.0030\n",
      "Epoch [52/100], Loss: 0.0024\n",
      "Epoch [53/100], Loss: 0.0026\n",
      "Epoch [54/100], Loss: 0.0024\n",
      "Epoch [55/100], Loss: 0.0023\n",
      "Epoch [56/100], Loss: 0.0022\n",
      "Epoch [57/100], Loss: 0.0028\n",
      "Epoch [58/100], Loss: 0.0021\n",
      "Epoch [59/100], Loss: 0.0019\n",
      "Epoch [60/100], Loss: 0.0023\n",
      "Epoch [61/100], Loss: 0.0019\n",
      "Epoch [62/100], Loss: 0.0019\n",
      "Epoch [63/100], Loss: 0.0017\n",
      "Epoch [64/100], Loss: 0.0016\n",
      "Epoch [65/100], Loss: 0.0016\n",
      "Epoch [66/100], Loss: 0.0015\n",
      "Epoch [67/100], Loss: 0.0013\n",
      "Epoch [68/100], Loss: 0.0014\n",
      "Epoch [69/100], Loss: 0.0013\n",
      "Epoch [70/100], Loss: 0.0013\n",
      "Epoch [71/100], Loss: 0.0012\n",
      "Epoch [72/100], Loss: 0.0012\n",
      "Epoch [73/100], Loss: 0.0012\n",
      "Epoch [74/100], Loss: 0.0014\n",
      "Epoch [75/100], Loss: 0.0011\n",
      "Epoch [76/100], Loss: 0.0011\n",
      "Epoch [77/100], Loss: 0.0012\n",
      "Epoch [78/100], Loss: 0.0011\n",
      "Epoch [79/100], Loss: 0.0013\n",
      "Epoch [80/100], Loss: 0.0012\n",
      "Epoch [81/100], Loss: 0.0010\n",
      "Epoch [82/100], Loss: 0.0010\n",
      "Epoch [83/100], Loss: 0.0009\n",
      "Epoch [84/100], Loss: 0.0009\n",
      "Epoch [85/100], Loss: 0.0009\n",
      "Epoch [86/100], Loss: 0.0008\n",
      "Epoch [87/100], Loss: 0.0011\n",
      "Epoch [88/100], Loss: 0.0008\n",
      "Epoch [89/100], Loss: 0.0008\n",
      "Epoch [90/100], Loss: 0.0010\n",
      "Epoch [91/100], Loss: 0.0008\n",
      "Epoch [92/100], Loss: 0.0008\n",
      "Epoch [93/100], Loss: 0.0008\n",
      "Epoch [94/100], Loss: 0.0008\n",
      "Epoch [95/100], Loss: 0.0006\n",
      "Epoch [96/100], Loss: 0.0007\n",
      "Epoch [97/100], Loss: 0.0007\n",
      "Epoch [98/100], Loss: 0.0007\n",
      "Epoch [99/100], Loss: 0.0006\n",
      "Epoch [100/100], Loss: 0.0007\n",
      "Validação - Modelo 2\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 2\n",
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model2 = CNNModel_2(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model2 = train_model(model2, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 2\")\n",
    "evaluate_model(model2, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 2\")\n",
    "evaluate_model(model2, test_loader)\n",
    "\n",
    "torch.save(model2.state_dict(), \"../outputs/models/model_task2_cnn2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 4.2357\n",
      "Epoch [2/100], Loss: 1.9221\n",
      "Epoch [3/100], Loss: 1.1928\n",
      "Epoch [4/100], Loss: 1.5472\n",
      "Epoch [5/100], Loss: 0.6307\n",
      "Epoch [6/100], Loss: 0.3455\n",
      "Epoch [7/100], Loss: 0.5239\n",
      "Epoch [8/100], Loss: 0.4486\n",
      "Epoch [9/100], Loss: 0.0568\n",
      "Epoch [10/100], Loss: 0.1511\n",
      "Epoch [11/100], Loss: 0.0928\n",
      "Epoch [12/100], Loss: 0.2287\n",
      "Epoch [13/100], Loss: 0.0276\n",
      "Epoch [14/100], Loss: 0.4409\n",
      "Epoch [15/100], Loss: 0.0475\n",
      "Epoch [16/100], Loss: 0.0026\n",
      "Epoch [17/100], Loss: 0.0180\n",
      "Epoch [18/100], Loss: 0.0077\n",
      "Epoch [19/100], Loss: 0.0097\n",
      "Epoch [20/100], Loss: 0.0014\n",
      "Epoch [21/100], Loss: 0.0012\n",
      "Epoch [22/100], Loss: 0.0001\n",
      "Epoch [23/100], Loss: 0.0003\n",
      "Epoch [24/100], Loss: 0.0009\n",
      "Epoch [25/100], Loss: 0.0009\n",
      "Epoch [26/100], Loss: 0.0002\n",
      "Epoch [27/100], Loss: 0.0010\n",
      "Epoch [28/100], Loss: 0.0002\n",
      "Epoch [29/100], Loss: 0.0018\n",
      "Epoch [30/100], Loss: 0.0002\n",
      "Epoch [31/100], Loss: 0.0033\n",
      "Epoch [32/100], Loss: 0.0013\n",
      "Epoch [33/100], Loss: 0.0006\n",
      "Epoch [34/100], Loss: 0.0001\n",
      "Epoch [35/100], Loss: 0.0036\n",
      "Epoch [36/100], Loss: 0.0004\n",
      "Epoch [37/100], Loss: 0.0011\n",
      "Epoch [38/100], Loss: 0.0001\n",
      "Epoch [39/100], Loss: 0.0005\n",
      "Epoch [40/100], Loss: 0.0000\n",
      "Epoch [41/100], Loss: 0.0001\n",
      "Epoch [42/100], Loss: 0.0007\n",
      "Epoch [43/100], Loss: 0.0165\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Epoch [45/100], Loss: 0.0017\n",
      "Epoch [46/100], Loss: 0.0100\n",
      "Epoch [47/100], Loss: 0.0004\n",
      "Epoch [48/100], Loss: 0.0016\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [51/100], Loss: 0.0001\n",
      "Epoch [52/100], Loss: 0.0004\n",
      "Epoch [53/100], Loss: 0.0001\n",
      "Epoch [54/100], Loss: 0.0002\n",
      "Epoch [55/100], Loss: 0.0005\n",
      "Epoch [56/100], Loss: 0.0001\n",
      "Epoch [57/100], Loss: 0.0001\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0002\n",
      "Epoch [61/100], Loss: 0.0012\n",
      "Epoch [62/100], Loss: 0.0000\n",
      "Epoch [63/100], Loss: 0.0002\n",
      "Epoch [64/100], Loss: 0.0002\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [66/100], Loss: 0.0003\n",
      "Epoch [67/100], Loss: 0.0002\n",
      "Epoch [68/100], Loss: 0.0006\n",
      "Epoch [69/100], Loss: 0.0002\n",
      "Epoch [70/100], Loss: 0.0031\n",
      "Epoch [71/100], Loss: 0.0001\n",
      "Epoch [72/100], Loss: 0.0000\n",
      "Epoch [73/100], Loss: 0.0001\n",
      "Epoch [74/100], Loss: 0.0001\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Epoch [76/100], Loss: 0.0001\n",
      "Epoch [77/100], Loss: 0.0006\n",
      "Epoch [78/100], Loss: 0.0003\n",
      "Epoch [79/100], Loss: 0.0002\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [81/100], Loss: 0.0002\n",
      "Epoch [82/100], Loss: 0.0000\n",
      "Epoch [83/100], Loss: 0.0001\n",
      "Epoch [84/100], Loss: 0.0001\n",
      "Epoch [85/100], Loss: 0.0000\n",
      "Epoch [86/100], Loss: 0.0001\n",
      "Epoch [87/100], Loss: 0.0001\n",
      "Epoch [88/100], Loss: 0.0009\n",
      "Epoch [89/100], Loss: 0.0039\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [91/100], Loss: 0.0001\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Epoch [93/100], Loss: 0.0008\n",
      "Epoch [94/100], Loss: 0.0001\n",
      "Epoch [95/100], Loss: 0.0000\n",
      "Epoch [96/100], Loss: 0.0005\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Epoch [98/100], Loss: 0.0006\n",
      "Epoch [99/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Validação - Modelo 3\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 3\n",
      "Accuracy: 40.00%\n"
     ]
    }
   ],
   "source": [
    "model3 = CNNModel_3(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model3 = train_model(model3, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 3\")\n",
    "evaluate_model(model3, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 3\")\n",
    "evaluate_model(model3, test_loader)\n",
    "\n",
    "torch.save(model3.state_dict(), \"../outputs/models/model_task2_cnn3.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 8.6049\n",
      "Epoch [2/100], Loss: 8.4234\n",
      "Epoch [3/100], Loss: 6.4934\n",
      "Epoch [4/100], Loss: 3.9202\n",
      "Epoch [5/100], Loss: 3.8293\n",
      "Epoch [6/100], Loss: 0.8885\n",
      "Epoch [7/100], Loss: 0.1558\n",
      "Epoch [8/100], Loss: 0.0006\n",
      "Epoch [9/100], Loss: 0.5408\n",
      "Epoch [10/100], Loss: 0.0000\n",
      "Epoch [11/100], Loss: 0.0001\n",
      "Epoch [12/100], Loss: 0.0022\n",
      "Epoch [13/100], Loss: 0.0641\n",
      "Epoch [14/100], Loss: 0.0002\n",
      "Epoch [15/100], Loss: 0.0006\n",
      "Epoch [16/100], Loss: 0.0024\n",
      "Epoch [17/100], Loss: 0.0018\n",
      "Epoch [18/100], Loss: 0.0013\n",
      "Epoch [19/100], Loss: 0.0001\n",
      "Epoch [20/100], Loss: 0.0000\n",
      "Epoch [21/100], Loss: 0.0000\n",
      "Epoch [22/100], Loss: 0.0000\n",
      "Epoch [23/100], Loss: 0.0001\n",
      "Epoch [24/100], Loss: 0.0000\n",
      "Epoch [25/100], Loss: 0.0000\n",
      "Epoch [26/100], Loss: 0.0000\n",
      "Epoch [27/100], Loss: 0.0000\n",
      "Epoch [28/100], Loss: 0.0000\n",
      "Epoch [29/100], Loss: 0.0000\n",
      "Epoch [30/100], Loss: 0.0000\n",
      "Epoch [31/100], Loss: 0.0000\n",
      "Epoch [32/100], Loss: 0.0000\n",
      "Epoch [33/100], Loss: 0.0000\n",
      "Epoch [34/100], Loss: 0.0000\n",
      "Epoch [35/100], Loss: 0.0001\n",
      "Epoch [36/100], Loss: 0.0000\n",
      "Epoch [37/100], Loss: 0.0000\n",
      "Epoch [38/100], Loss: 0.0000\n",
      "Epoch [39/100], Loss: 0.0000\n",
      "Epoch [40/100], Loss: 0.0000\n",
      "Epoch [41/100], Loss: 0.0000\n",
      "Epoch [42/100], Loss: 0.0000\n",
      "Epoch [43/100], Loss: 0.0000\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Epoch [45/100], Loss: 0.0000\n",
      "Epoch [46/100], Loss: 0.0000\n",
      "Epoch [47/100], Loss: 0.0000\n",
      "Epoch [48/100], Loss: 0.0000\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Epoch [50/100], Loss: 0.0000\n",
      "Epoch [51/100], Loss: 0.0000\n",
      "Epoch [52/100], Loss: 0.0000\n",
      "Epoch [53/100], Loss: 0.0000\n",
      "Epoch [54/100], Loss: 0.0000\n",
      "Epoch [55/100], Loss: 0.0000\n",
      "Epoch [56/100], Loss: 0.0000\n",
      "Epoch [57/100], Loss: 0.0000\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Epoch [61/100], Loss: 0.0000\n",
      "Epoch [62/100], Loss: 0.0000\n",
      "Epoch [63/100], Loss: 0.0000\n",
      "Epoch [64/100], Loss: 0.0000\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [66/100], Loss: 0.0000\n",
      "Epoch [67/100], Loss: 0.0000\n",
      "Epoch [68/100], Loss: 0.0000\n",
      "Epoch [69/100], Loss: 0.0000\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [71/100], Loss: 0.0000\n",
      "Epoch [72/100], Loss: 0.0000\n",
      "Epoch [73/100], Loss: 0.0000\n",
      "Epoch [74/100], Loss: 0.0000\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Epoch [76/100], Loss: 0.0000\n",
      "Epoch [77/100], Loss: 0.0000\n",
      "Epoch [78/100], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model4 = CNNModel_4(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model4 = train_model(model4, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 4\")\n",
    "evaluate_model(model4, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 4\")\n",
    "evaluate_model(model4, test_loader)\n",
    "\n",
    "torch.save(model4.state_dict(), \"../outputs/models/model_task2_cnn4.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrigindo escala de labels de 1–5 para 0–4...\n"
     ]
    }
   ],
   "source": [
    "frame_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def load_video_frames(video_path, max_frames=16):\n",
    "    frames = sorted(video_path.glob(\"*.jpg\"))[:max_frames]\n",
    "    video_tensor = torch.stack([frame_transform(Image.open(f).convert(\"RGB\")) for f in frames])\n",
    "    if len(frames) < max_frames:\n",
    "        padding = torch.zeros((max_frames - len(frames), 3, 224, 224))\n",
    "        video_tensor = torch.cat([video_tensor, padding], dim=0)\n",
    "    return video_tensor\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    video_id = row[\"VIDEO\"]\n",
    "    video_dir = FRAME_DIR / video_id\n",
    "    if not video_dir.exists():\n",
    "        continue\n",
    "    video_tensor = load_video_frames(video_dir, max_frames=16)\n",
    "    labels = torch.tensor([\n",
    "        row[\"OSATS_RESPECT\"], row[\"OSATS_MOTION\"], row[\"OSATS_INSTRUMENT\"],\n",
    "        row[\"OSATS_SUTURE\"], row[\"OSATS_FLOW\"], row[\"OSATS_KNOWLEDGE\"],\n",
    "        row[\"OSATS_PERFORMANCE\"], row[\"OSATS_FINAL_QUALITY\"]\n",
    "    ], dtype=torch.long)\n",
    "    X.append(video_tensor)\n",
    "    y.append(labels)\n",
    "\n",
    "X = torch.stack(X)\n",
    "y = torch.stack(y)\n",
    "\n",
    "# Corrigir labels se estiverem na escala 1–5 (passar para 0–4)\n",
    "if torch.any(y > 4):\n",
    "    print(\"Corrigindo escala de labels de 1–5 para 0–4...\")\n",
    "    y = y - 1\n",
    "\n",
    "# Verificação de segurança\n",
    "assert torch.all((y >= 0) & (y <= 4)), \"Erro: targets fora do intervalo 0–4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class OSATSDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = OSATSDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()\n",
    "        self.backbone = resnet\n",
    "        self.fc_shared = nn.Linear(512, 128)\n",
    "        self.heads = nn.ModuleList([nn.Linear(128, 5) for _ in range(8)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feat = self.backbone(x).view(B, T, -1)\n",
    "        feat = feat.mean(dim=1)\n",
    "        shared = F.relu(self.fc_shared(feat))\n",
    "        return torch.stack([head(shared) for head in self.heads], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    loss = 0\n",
    "    for i in range(8):\n",
    "        loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    return loss / 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100 - Loss treino: 1.6557\n",
      "Época 2/100 - Loss treino: 1.3940\n",
      "Época 3/100 - Loss treino: 1.2120\n",
      "Época 4/100 - Loss treino: 1.0552\n",
      "Época 5/100 - Loss treino: 0.9106\n",
      "Época 6/100 - Loss treino: 0.7806\n",
      "Época 7/100 - Loss treino: 0.6666\n",
      "Época 8/100 - Loss treino: 0.5685\n",
      "Época 9/100 - Loss treino: 0.4842\n",
      "Época 10/100 - Loss treino: 0.4102\n",
      "Época 11/100 - Loss treino: 0.3460\n",
      "Época 12/100 - Loss treino: 0.2908\n",
      "Época 13/100 - Loss treino: 0.2446\n",
      "Época 14/100 - Loss treino: 0.2060\n",
      "Época 15/100 - Loss treino: 0.1730\n",
      "Época 16/100 - Loss treino: 0.1453\n",
      "Época 17/100 - Loss treino: 0.1220\n",
      "Época 18/100 - Loss treino: 0.1022\n",
      "Época 19/100 - Loss treino: 0.0854\n",
      "Época 20/100 - Loss treino: 0.0716\n",
      "Época 21/100 - Loss treino: 0.0603\n",
      "Época 22/100 - Loss treino: 0.0510\n",
      "Época 23/100 - Loss treino: 0.0433\n",
      "Época 24/100 - Loss treino: 0.0371\n",
      "Época 25/100 - Loss treino: 0.0319\n",
      "Época 26/100 - Loss treino: 0.0276\n",
      "Época 27/100 - Loss treino: 0.0241\n",
      "Época 28/100 - Loss treino: 0.0211\n",
      "Época 29/100 - Loss treino: 0.0187\n",
      "Época 30/100 - Loss treino: 0.0166\n",
      "Época 31/100 - Loss treino: 0.0149\n",
      "Época 32/100 - Loss treino: 0.0134\n",
      "Época 33/100 - Loss treino: 0.0121\n",
      "Época 34/100 - Loss treino: 0.0110\n",
      "Época 35/100 - Loss treino: 0.0101\n",
      "Época 36/100 - Loss treino: 0.0092\n",
      "Época 37/100 - Loss treino: 0.0085\n",
      "Época 38/100 - Loss treino: 0.0079\n",
      "Época 39/100 - Loss treino: 0.0073\n",
      "Época 40/100 - Loss treino: 0.0068\n",
      "Época 41/100 - Loss treino: 0.0064\n",
      "Época 42/100 - Loss treino: 0.0060\n",
      "Época 43/100 - Loss treino: 0.0057\n",
      "Época 44/100 - Loss treino: 0.0053\n",
      "Época 45/100 - Loss treino: 0.0051\n",
      "Época 46/100 - Loss treino: 0.0048\n",
      "Época 47/100 - Loss treino: 0.0046\n",
      "Época 48/100 - Loss treino: 0.0044\n",
      "Época 49/100 - Loss treino: 0.0042\n",
      "Época 50/100 - Loss treino: 0.0040\n",
      "Época 51/100 - Loss treino: 0.0039\n",
      "Época 52/100 - Loss treino: 0.0037\n",
      "Época 53/100 - Loss treino: 0.0036\n",
      "Época 54/100 - Loss treino: 0.0034\n",
      "Época 55/100 - Loss treino: 0.0033\n",
      "Época 56/100 - Loss treino: 0.0032\n",
      "Época 57/100 - Loss treino: 0.0031\n",
      "Época 58/100 - Loss treino: 0.0030\n",
      "Época 59/100 - Loss treino: 0.0029\n",
      "Época 60/100 - Loss treino: 0.0029\n",
      "Época 61/100 - Loss treino: 0.0028\n",
      "Época 62/100 - Loss treino: 0.0027\n",
      "Época 63/100 - Loss treino: 0.0027\n",
      "Época 64/100 - Loss treino: 0.0026\n",
      "Época 65/100 - Loss treino: 0.0025\n",
      "Época 66/100 - Loss treino: 0.0025\n",
      "Época 67/100 - Loss treino: 0.0024\n",
      "Época 68/100 - Loss treino: 0.0024\n",
      "Época 69/100 - Loss treino: 0.0023\n",
      "Época 70/100 - Loss treino: 0.0023\n",
      "Época 71/100 - Loss treino: 0.0022\n",
      "Época 72/100 - Loss treino: 0.0022\n",
      "Época 73/100 - Loss treino: 0.0021\n",
      "Época 74/100 - Loss treino: 0.0021\n",
      "Época 75/100 - Loss treino: 0.0021\n",
      "Época 76/100 - Loss treino: 0.0020\n",
      "Época 77/100 - Loss treino: 0.0020\n",
      "Época 78/100 - Loss treino: 0.0020\n",
      "Época 79/100 - Loss treino: 0.0019\n",
      "Época 80/100 - Loss treino: 0.0019\n",
      "Época 81/100 - Loss treino: 0.0019\n",
      "Época 82/100 - Loss treino: 0.0018\n",
      "Época 83/100 - Loss treino: 0.0018\n",
      "Época 84/100 - Loss treino: 0.0018\n",
      "Época 85/100 - Loss treino: 0.0017\n",
      "Época 86/100 - Loss treino: 0.0017\n",
      "Época 87/100 - Loss treino: 0.0017\n",
      "Época 88/100 - Loss treino: 0.0017\n",
      "Época 89/100 - Loss treino: 0.0016\n",
      "Época 90/100 - Loss treino: 0.0016\n",
      "Época 91/100 - Loss treino: 0.0016\n",
      "Época 92/100 - Loss treino: 0.0016\n",
      "Época 93/100 - Loss treino: 0.0016\n",
      "Época 94/100 - Loss treino: 0.0015\n",
      "Época 95/100 - Loss treino: 0.0015\n",
      "Época 96/100 - Loss treino: 0.0015\n",
      "Época 97/100 - Loss treino: 0.0015\n",
      "Época 98/100 - Loss treino: 0.0014\n",
      "Época 99/100 - Loss treino: 0.0014\n",
      "Época 100/100 - Loss treino: 0.0014\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        preds = torch.argmax(outputs, dim=2)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo após treino\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_resnet.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSResNetGRU(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()\n",
    "        self.backbone = resnet  \n",
    "\n",
    "        self.gru = nn.GRU(input_size=512, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.heads = nn.ModuleList([nn.Linear(hidden_size, 5) for _ in range(8)])  \n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        features = self.backbone(x)  \n",
    "        features = features.view(B, T, 512) \n",
    "\n",
    "        _, h_n = self.gru(features) \n",
    "        h_n = h_n.squeeze(0) \n",
    "\n",
    "        return torch.stack([head(h_n) for head in self.heads], dim=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(preds, targets):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(preds.size(1)):  # 8 cabeças\n",
    "        total_loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    \n",
    "    return total_loss / preds.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100 - Loss treino: 1.6299\n",
      "Época 2/100 - Loss treino: 1.0909\n",
      "Época 3/100 - Loss treino: 0.8264\n",
      "Época 4/100 - Loss treino: 0.6919\n",
      "Época 5/100 - Loss treino: 0.6110\n",
      "Época 6/100 - Loss treino: 0.5569\n",
      "Época 7/100 - Loss treino: 0.5152\n",
      "Época 8/100 - Loss treino: 0.4811\n",
      "Época 9/100 - Loss treino: 0.4531\n",
      "Época 10/100 - Loss treino: 0.4297\n",
      "Época 11/100 - Loss treino: 0.4091\n",
      "Época 12/100 - Loss treino: 0.3904\n",
      "Época 13/100 - Loss treino: 0.3731\n",
      "Época 14/100 - Loss treino: 0.3571\n",
      "Época 15/100 - Loss treino: 0.3432\n",
      "Época 16/100 - Loss treino: 0.3299\n",
      "Época 17/100 - Loss treino: 0.3176\n",
      "Época 18/100 - Loss treino: 0.3064\n",
      "Época 19/100 - Loss treino: 0.2957\n",
      "Época 20/100 - Loss treino: 0.2857\n",
      "Época 21/100 - Loss treino: 0.2763\n",
      "Época 22/100 - Loss treino: 0.2673\n",
      "Época 23/100 - Loss treino: 0.2587\n",
      "Época 24/100 - Loss treino: 0.2504\n",
      "Época 25/100 - Loss treino: 0.2426\n",
      "Época 26/100 - Loss treino: 0.2351\n",
      "Época 27/100 - Loss treino: 0.2280\n",
      "Época 28/100 - Loss treino: 0.2212\n",
      "Época 29/100 - Loss treino: 0.2147\n",
      "Época 30/100 - Loss treino: 0.2085\n",
      "Época 31/100 - Loss treino: 0.2025\n",
      "Época 32/100 - Loss treino: 0.1969\n",
      "Época 33/100 - Loss treino: 0.1915\n",
      "Época 34/100 - Loss treino: 0.1864\n",
      "Época 35/100 - Loss treino: 0.1815\n",
      "Época 36/100 - Loss treino: 0.1767\n",
      "Época 37/100 - Loss treino: 0.1722\n",
      "Época 38/100 - Loss treino: 0.1679\n",
      "Época 39/100 - Loss treino: 0.1637\n",
      "Época 40/100 - Loss treino: 0.1597\n",
      "Época 41/100 - Loss treino: 0.1558\n",
      "Época 42/100 - Loss treino: 0.1519\n",
      "Época 43/100 - Loss treino: 0.1483\n",
      "Época 44/100 - Loss treino: 0.1449\n",
      "Época 45/100 - Loss treino: 0.1416\n",
      "Época 46/100 - Loss treino: 0.1384\n",
      "Época 47/100 - Loss treino: 0.1353\n",
      "Época 48/100 - Loss treino: 0.1324\n",
      "Época 49/100 - Loss treino: 0.1295\n",
      "Época 50/100 - Loss treino: 0.1267\n",
      "Época 51/100 - Loss treino: 0.1241\n",
      "Época 52/100 - Loss treino: 0.1216\n",
      "Época 53/100 - Loss treino: 0.1191\n",
      "Época 54/100 - Loss treino: 0.1168\n",
      "Época 55/100 - Loss treino: 0.1145\n",
      "Época 56/100 - Loss treino: 0.1123\n",
      "Época 57/100 - Loss treino: 0.1101\n",
      "Época 58/100 - Loss treino: 0.1081\n",
      "Época 59/100 - Loss treino: 0.1061\n",
      "Época 60/100 - Loss treino: 0.1041\n",
      "Época 61/100 - Loss treino: 0.1023\n",
      "Época 62/100 - Loss treino: 0.1004\n",
      "Época 63/100 - Loss treino: 0.0987\n",
      "Época 64/100 - Loss treino: 0.0970\n",
      "Época 65/100 - Loss treino: 0.0953\n",
      "Época 66/100 - Loss treino: 0.0937\n",
      "Época 67/100 - Loss treino: 0.0922\n",
      "Época 68/100 - Loss treino: 0.0906\n",
      "Época 69/100 - Loss treino: 0.0892\n",
      "Época 70/100 - Loss treino: 0.0877\n",
      "Época 71/100 - Loss treino: 0.0864\n",
      "Época 72/100 - Loss treino: 0.0850\n",
      "Época 73/100 - Loss treino: 0.0837\n",
      "Época 74/100 - Loss treino: 0.0824\n",
      "Época 75/100 - Loss treino: 0.0812\n",
      "Época 76/100 - Loss treino: 0.0799\n",
      "Época 77/100 - Loss treino: 0.0788\n",
      "Época 78/100 - Loss treino: 0.0776\n",
      "Época 79/100 - Loss treino: 0.0765\n",
      "Época 80/100 - Loss treino: 0.0754\n",
      "Época 81/100 - Loss treino: 0.0743\n",
      "Época 82/100 - Loss treino: 0.0733\n",
      "Época 83/100 - Loss treino: 0.0722\n",
      "Época 84/100 - Loss treino: 0.0712\n",
      "Época 85/100 - Loss treino: 0.0703\n",
      "Época 86/100 - Loss treino: 0.0693\n",
      "Época 87/100 - Loss treino: 0.0684\n",
      "Época 88/100 - Loss treino: 0.0675\n",
      "Época 89/100 - Loss treino: 0.0666\n",
      "Época 90/100 - Loss treino: 0.0657\n",
      "Época 91/100 - Loss treino: 0.0649\n",
      "Época 92/100 - Loss treino: 0.0640\n",
      "Época 93/100 - Loss treino: 0.0632\n",
      "Época 94/100 - Loss treino: 0.0624\n",
      "Época 95/100 - Loss treino: 0.0616\n",
      "Época 96/100 - Loss treino: 0.0609\n",
      "Época 97/100 - Loss treino: 0.0601\n",
      "Época 98/100 - Loss treino: 0.0594\n",
      "Época 99/100 - Loss treino: 0.0587\n",
      "Época 100/100 - Loss treino: 0.0580\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSResNetGRU().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_resnet_gru.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer (ViT) + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vit = models.vit_b_16(pretrained=True)\n",
    "        vit.heads = nn.Identity()  # remover a cabeça original\n",
    "        self.backbone = vit  # saída: [B*T, 768]\n",
    "\n",
    "        self.shared = nn.Linear(768, 128)\n",
    "        self.heads = nn.ModuleList([nn.Linear(128, 5) for _ in range(8)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)             # [B*T, 3, 224, 224]\n",
    "        features = self.backbone(x)            # [B*T, 768]\n",
    "        features = features.view(B, T, -1)     # [B, T, 768]\n",
    "        pooled = features.mean(dim=1)          # média temporal → [B, 768]\n",
    "\n",
    "        shared = F.relu(self.shared(pooled))   # [B, 128]\n",
    "        return torch.stack([head(shared) for head in self.heads], dim=1)  # [B, 8, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(preds, targets):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(preds.size(1)):  # 8 cabeças\n",
    "        total_loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    \n",
    "    return total_loss / preds.size(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/luis/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [11:05<00:00, 520kB/s] \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_vit.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_multihead(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # [B, 8, 5]\n",
    "            loss = criterion(outputs.view(-1, 5), targets.view(-1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=2)  # [B, 8]\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_items += targets.numel()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_acc = total_correct / total_items\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CNNModel_1().to(device)\n",
    "model1.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn1.pt\"))\n",
    "\n",
    "model2 = CNNModel_2().to(device)\n",
    "model2.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn2.pt\"))\n",
    "\n",
    "model3 = CNNModel_3().to(device)\n",
    "model3.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn3.pt\"))\n",
    "\n",
    "model4 = CNNModel_4().to(device)\n",
    "model4.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn4.pt\"))\n",
    "\n",
    "model5 = OSATSResNet().to(device)\n",
    "model5.load_state_dict(torch.load(\"../outputs/models/model_task2_resnet.pt\"))\n",
    "\n",
    "model6 = OSATSResNetGRU().to(device)\n",
    "model6.load_state_dict(torch.load(\"../outputs/models/model_task2_resnet_gru.pt\"))\n",
    "\n",
    "model7 = OSATSViT().to(device)\n",
    "model7.load_state_dict(torch.load(\"../outputs/models/model_task2_vit.pt\"))\n",
    "\n",
    "models = {\n",
    "    \"CNNModel_1\": model1,\n",
    "    \"CNNModel_2\": model2,\n",
    "    \"CNNModel_3\": model3,\n",
    "    \"CNNModel_4\": model4,\n",
    "    \"ResNet + MLP\": model5,\n",
    "    \"ResNet + GRU\": model6,\n",
    "    \"ViT + MLP\": model7\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico de Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([h[0] for h in hist1], label='CNNModel_1 Loss')\n",
    "plt.plot([h[0] for h in hist2], label='CNNModel_2 Loss')\n",
    "plt.plot([h[0] for h in hist3], label='CNNModel_3 Loss')\n",
    "plt.plot([h[0] for h in hist4], label='CNNModel_4 Loss')\n",
    "plt.plot([h[0] for h in hist5], label='CNNLSTM Loss')\n",
    "plt.plot([h[0] for h in hist6], label='EfficientNetLSTM Loss')\n",
    "plt.plot([h[0] for h in hist7], label='ViTLSTM Loss')\n",
    "plt.title('Loss durante treino')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Gráfico de Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([h[1] for h in hist1], label='CNNModel_1 Accuracy')\n",
    "plt.plot([h[1] for h in hist2], label='CNNModel_2 Accuracy')\n",
    "plt.plot([h[1] for h in hist3], label='CNNModel_3 Accuracy')\n",
    "plt.plot([h[1] for h in hist4], label='CNNModel_4 Accuracy')\n",
    "plt.plot([h[1] for h in hist5], label='CNNLSTM Accuracy')\n",
    "plt.plot([h[1] for h in hist6], label='EfficientNetLSTM Accuracy')\n",
    "plt.plot([h[1] for h in hist7], label='ViTLSTM Accuracy')\n",
    "plt.title('Accuracy durante treino')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "val_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    val_loss, val_acc = validate_model_multihead(model, val_loader, criterion)\n",
    "    val_results[name] = val_acc\n",
    "    print(f\"{name} - Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(val_results, key=val_results.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Melhor modelo: {best_model_name} com accuracy {val_results[best_model_name]:.4f}\")\n",
    "\n",
    "test_loss, test_acc = validate_model_multihead(best_model, test_loader, criterion)\n",
    "print(f\"Acurácia no Teste: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "osats_cols = [col for col in df.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "best_model.eval()\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        preds = outputs.argmax(dim=2)\n",
    "\n",
    "        all_true.append(targets.cpu())\n",
    "        all_pred.append(preds.cpu())\n",
    "\n",
    "true = torch.cat(all_true)\n",
    "pred = torch.cat(all_pred)\n",
    "\n",
    "for i, col in enumerate(osats_cols):\n",
    "    cm = confusion_matrix(true[:, i], pred[:, i])\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Matriz de Confusão - {col}\")\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Verdadeiro\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
