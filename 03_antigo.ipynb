{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "FRAME_DIR = Path(\"../data/frames\")\n",
    "LABEL_PATH = Path(\"../data/labels/labels_task1.csv\")\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 2\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 4\n",
    "SEQUENCE_LENGTH = 16\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeos disponíveis com frames: 30\n"
     ]
    }
   ],
   "source": [
    "# Carregar labels\n",
    "df = pd.read_csv(LABEL_PATH)\n",
    "\n",
    "# Verificar vídeos com frames extraídos\n",
    "available_videos = {p.name for p in FRAME_DIR.iterdir() if p.is_dir() and any(p.glob(\"*.jpg\"))}\n",
    "df = df[df[\"VIDEO\"].isin(available_videos)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Vídeos disponíveis com frames: {len(df)}\")\n",
    "\n",
    "# Guardar labels filtradas temporariamente\n",
    "df.to_csv(\"../data/labels/filtered_labels_task1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRSDataset(Dataset):\n",
    "    def __init__(self, df, frame_dir, transform=None, sequence_length=16):\n",
    "        self.data = df\n",
    "        self.frame_dir = Path(frame_dir)\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        video_id = row[\"VIDEO\"]\n",
    "        label = row[\"GRS\"]\n",
    "        frame_path = self.frame_dir / video_id\n",
    "\n",
    "        # Carregar lista de frames\n",
    "        frames = sorted(list(frame_path.glob(\"*.jpg\")))\n",
    "        if len(frames) == 0:\n",
    "            raise IndexError(f\"Nenhum frame encontrado para o vídeo {video_id} em {frame_path}\")\n",
    "\n",
    "        selected = frames[:self.sequence_length]\n",
    "        while len(selected) < self.sequence_length:\n",
    "            selected.append(selected[-1])  # repetir último frame\n",
    "\n",
    "        images = [self.transform(Image.open(f).convert(\"RGB\")) for f in selected]\n",
    "        images = torch.stack(images)\n",
    "\n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = GRSDataset(df, FRAME_DIR, transform, sequence_length=SEQUENCE_LENGTH)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRSClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.cnn = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feats = self.cnn(x)\n",
    "        feats = feats.view(B, T, 512)\n",
    "        lstm_out, _ = self.lstm(feats)\n",
    "        out = self.fc(lstm_out[:, -1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 19.8555 | Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Loss: 11.9393 | Acc: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:18<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Loss: 7.1890 | Acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:20<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Loss: 4.0895 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:18<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Loss: 2.8734 | Acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Loss: 1.8131 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Loss: 1.3714 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Loss: 0.9774 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Loss: 0.8520 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Loss: 0.6703 | Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GRSClassifier(NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f} | Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"../outputs/models/grs_classifier.pt\")\n",
    "print(\"✅ Modelo salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão: [0 2]\n",
      "Label real: [0 2]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "x, y = sample\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred = model(x.to(device))\n",
    "    print(\"Previsão:\", pred.argmax(dim=1).cpu().numpy())\n",
    "    print(\"Label real:\", y.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
